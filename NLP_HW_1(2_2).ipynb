{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c0HC8_9oQjG",
        "outputId": "d6c010d6-c9f5-4e0a-8ad9-9a8aeb95c22e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: best pair = ('l', 'o'), count = 2, vocab size = 11\n",
            "Step 2: best pair = ('lo', 'w'), count = 2, vocab size = 10\n",
            "Step 3: best pair = ('e', 's'), count = 2, vocab size = 10\n",
            "Step 4: best pair = ('es', 't'), count = 2, vocab size = 10\n",
            "Step 5: best pair = ('est', '_'), count = 2, vocab size = 9\n",
            "Step 6: best pair = ('n', 'e'), count = 2, vocab size = 9\n",
            "Step 7: best pair = ('ne', 'w'), count = 2, vocab size = 9\n",
            "Step 8: best pair = ('w', 'i'), count = 2, vocab size = 9\n",
            "Step 9: best pair = ('wi', 'd'), count = 2, vocab size = 8\n",
            "Step 10: best pair = ('low', '_'), count = 1, vocab size = 7\n",
            "new -> ['new', '_']\n",
            "newer -> ['new', 'er_']\n",
            "lowest -> ['low', 'est_']\n",
            "widest -> ['wide', 's', 't', '_']\n",
            "earnest -> ['e', 'a', 'r', 'n', 'est_']\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter, defaultdict\n",
        "\n",
        "# Toy corpus\n",
        "corpus_words = [\"low\", \"lowest\", \"new\", \"newer\", \"wide\", \"widest\"]\n",
        "\n",
        "def word_to_symbols(word):\n",
        "    return list(word) + [\"_\"]  # add end-of-word marker\n",
        "\n",
        "corpus = [word_to_symbols(w) for w in corpus_words]\n",
        "\n",
        "def get_pair_counts(corpus):\n",
        "    pair_counts = Counter()\n",
        "    for word in corpus:\n",
        "        for i in range(len(word) - 1):\n",
        "            pair = (word[i], word[i+1])\n",
        "            pair_counts[pair] += 1\n",
        "    return pair_counts\n",
        "\n",
        "def merge_pair(corpus, pair):\n",
        "    new_corpus = []\n",
        "    bigram = list(pair)\n",
        "    merged = \"\".join(bigram)\n",
        "    for word in corpus:\n",
        "        i = 0\n",
        "        new_word = []\n",
        "        while i < len(word):\n",
        "            if i < len(word) - 1 and word[i] == bigram[0] and word[i+1] == bigram[1]:\n",
        "                new_word.append(merged)\n",
        "                i += 2\n",
        "            else:\n",
        "                new_word.append(word[i])\n",
        "                i += 1\n",
        "        new_corpus.append(new_word)\n",
        "    return new_corpus\n",
        "\n",
        "def vocab_from_corpus(corpus):\n",
        "    vocab = set()\n",
        "    for word in corpus:\n",
        "        vocab.update(word)\n",
        "    return vocab\n",
        "\n",
        "# Learn BPE merges\n",
        "num_merges = 10\n",
        "corpus_bpe = corpus[:]\n",
        "\n",
        "for step in range(1, num_merges + 1):\n",
        "    pair_counts = get_pair_counts(corpus_bpe)\n",
        "    if not pair_counts:\n",
        "        break\n",
        "    best_pair, best_count = pair_counts.most_common(1)[0]\n",
        "    vocab_size = len(vocab_from_corpus(corpus_bpe))\n",
        "    print(f\"Step {step}: best pair = {best_pair}, count = {best_count}, vocab size = {vocab_size}\")\n",
        "    corpus_bpe = merge_pair(corpus_bpe, best_pair)\n",
        "    merges = [\"low\", \"new\", \"wide\", \"er_\", \"est_\"]  # example learned subwords\n",
        "\n",
        "def segment_word(word, merges):\n",
        "    symbols = list(word) + [\"_\"]\n",
        "    # Greedy longest-match over merges\n",
        "    changed = True\n",
        "    while changed:\n",
        "        changed = False\n",
        "        for m in sorted(merges, key=len, reverse=True):\n",
        "            m_list = list(m)\n",
        "            i = 0\n",
        "            while i <= len(symbols) - len(m_list):\n",
        "                if symbols[i:i+len(m_list)] == m_list:\n",
        "                    symbols = symbols[:i] + [\"\".join(m_list)] + symbols[i+len(m_list):]\n",
        "                    changed = True\n",
        "                else:\n",
        "                    i += 1\n",
        "    return symbols\n",
        "\n",
        "words_to_segment = [\"new\", \"newer\", \"lowest\", \"widest\", \"earnest\"]\n",
        "\n",
        "for w in words_to_segment:\n",
        "    print(w, \"->\", segment_word(w, merges))"
      ]
    }
  ]
}